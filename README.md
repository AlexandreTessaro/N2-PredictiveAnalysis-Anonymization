# Anonimiza√ß√£o de Dados - Conformidade com LGPD

## üìã Descri√ß√£o do Projeto

Este projeto implementa t√©cnicas de anonimiza√ß√£o de dados pessoais em conformidade com a **Lei Geral de Prote√ß√£o de Dados Pessoais (LGPD)** do Brasil. O objetivo √© demonstrar como utilizar dados sens√≠veis em an√°lises, predi√ß√µes e classifica√ß√µes sem desrespeitar a legisla√ß√£o de prote√ß√£o de dados.

## üéØ Objetivos

- Implementar t√©cnicas de anonimiza√ß√£o de dados conforme LGPD
- Demonstrar o trade-off entre utilidade dos dados e privacidade
- Fornecer ferramentas pr√°ticas para prote√ß√£o de dados pessoais
- Gerar visualiza√ß√µes comparativas das t√©cnicas aplicadas

## üîß T√©cnicas Implementadas

### 1. **K-Anonimidade**
- **Descri√ß√£o**: Garante que cada registro seja indistingu√≠vel de pelo menos k-1 outros registros
- **Aplica√ß√£o**: Agrupamento de registros baseado em atributos quasi-identificadores
- **Par√¢metros**: k=3 (m√≠nimo de 3 registros por grupo)

### 2. **L-Diversidade**
- **Descri√ß√£o**: Garante que cada grupo tenha pelo menos l valores distintos para o atributo sens√≠vel
- **Aplica√ß√£o**: Diversifica√ß√£o de valores sens√≠veis dentro dos grupos
- **Par√¢metros**: l=2 (m√≠nimo de 2 valores distintos)

### 3. **Generaliza√ß√£o**
- **Descri√ß√£o**: Substitui valores espec√≠ficos por categorias mais amplas
- **Aplica√ß√£o**: 
  - Idade ‚Üí Faixas et√°rias (18-25, 26-35, etc.)
  - Sal√°rio ‚Üí Faixas salariais (Baixo, M√©dio, Alto, etc.)
  - Localiza√ß√£o ‚Üí Cidade anonimizada

### 4. **Supress√£o**
- **Descri√ß√£o**: Remove completamente atributos identificadores diretos
- **Aplica√ß√£o**: Elimina√ß√£o de campos como CPF, RG, nome completo
- **Benef√≠cio**: Redu√ß√£o m√°xima de risco de reidentifica√ß√£o

### 5. **Pseudoanonimiza√ß√£o**
- **Descri√ß√£o**: Substitui identificadores por pseud√¥nimos usando hash
- **Aplica√ß√£o**: Email e telefone ‚Üí Hash SHA-256
- **Benef√≠cio**: Mant√©m utilidade para an√°lises agregadas

### 6. **Mascaramento de Dados**
- **Descri√ß√£o**: Substitui parte dos dados por caracteres de mascaramento
- **Aplica√ß√£o**:
  - Email: `j***@exemplo.com`
  - Telefone: `***-****-1234`
  - CPF: `123***.***-45`

### 7. **Adi√ß√£o de Ru√≠do**
- **Descri√ß√£o**: Adiciona ru√≠do aleat√≥rio aos dados num√©ricos
- **Aplica√ß√£o**: Sal√°rio, renda familiar, score de cr√©dito
- **Par√¢metros**: Ru√≠do gaussiano com 5% de desvio padr√£o

### 8. **Privacidade Diferencial**
- **Descri√ß√£o**: Adiciona ru√≠do calibrado para garantir privacidade diferencial
- **Aplica√ß√£o**: Dados num√©ricos sens√≠veis
- **Par√¢metros**: Œµ=1.0 (par√¢metro de privacidade)

## üìÅ Estrutura do Projeto

```
N2-PredictiveAnalysis/
‚îú‚îÄ‚îÄ requirements.txt                 # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ sample_data_generator.py        # Gerador de dados sens√≠veis
‚îú‚îÄ‚îÄ anonymization_techniques.py     # Implementa√ß√£o das t√©cnicas
‚îú‚îÄ‚îÄ demo_anonymization.py          # Demonstra√ß√£o completa
‚îú‚îÄ‚îÄ README.md                      # Documenta√ß√£o do projeto
‚îî‚îÄ‚îÄ dados_sensiveis_original.csv   # Dataset de exemplo (gerado)
```

## üöÄ Como Executar

### 1. Instala√ß√£o das Depend√™ncias

```bash
pip install -r requirements.txt
```

### 2. Gera√ß√£o de Dados de Exemplo

```bash
python sample_data_generator.py
```

### 3. Execu√ß√£o da Demonstra√ß√£o Completa

```bash
python demo_anonymization.py
```

### 4. Execu√ß√£o Individual das T√©cnicas

```bash
python anonymization_techniques.py
```

## üìä Sa√≠das Geradas

### Arquivos CSV
- `dados_sensiveis_original.csv` - Dataset original com dados sens√≠veis
- `dados_k_anonimidade.csv` - Dataset com K-anonimidade aplicada
- `dados_generalizados.csv` - Dataset com generaliza√ß√£o aplicada
- `dados_suprimidos.csv` - Dataset com supress√£o aplicada
- `dados_pseudoanonimizados.csv` - Dataset com pseudoanonimiza√ß√£o aplicada
- `dados_mascarados.csv` - Dataset com mascaramento aplicado
- `dados_com_ruido.csv` - Dataset com adi√ß√£o de ru√≠do
- `dados_privacidade_diferencial.csv` - Dataset com privacidade diferencial

### Visualiza√ß√µes
- `comparacao_anonimizacao.png` - Gr√°ficos comparativos das t√©cnicas
- `utilidade_vs_privacidade.png` - Trade-off utilidade vs privacidade

## üìà An√°lise de Resultados

### M√©tricas de Privacidade
- **K-Anonimidade**: Medida pelo n√∫mero m√≠nimo de registros por grupo
- **L-Diversidade**: Medida pela diversidade de valores sens√≠veis
- **Supress√£o**: Medida pela porcentagem de atributos removidos

### M√©tricas de Utilidade
- **Correla√ß√£o**: Mantida entre vari√°veis num√©ricas
- **Distribui√ß√£o**: Preservada para an√°lises estat√≠sticas
- **Agrega√ß√£o**: Poss√≠vel para an√°lises de tend√™ncias

### Trade-off Utilidade vs Privacidade
- **Alta Utilidade, Baixa Privacidade**: Pseudoanonimiza√ß√£o
- **Alta Privacidade, Baixa Utilidade**: Supress√£o
- **Equil√≠brio**: Generaliza√ß√£o + K-anonimidade

## üîí Conformidade com LGPD

### Princ√≠pios Aplicados
1. **Finalidade**: Dados anonimizados para an√°lise estat√≠stica
2. **Adequa√ß√£o**: T√©cnicas adequadas ao prop√≥sito
3. **Necessidade**: M√≠nimo necess√°rio para an√°lise
4. **Transpar√™ncia**: Processo documentado e audit√°vel
5. **Seguran√ßa**: Prote√ß√£o contra reidentifica√ß√£o

### Direitos dos Titulares
- **Anonimiza√ß√£o**: Dados n√£o podem ser reidentificados
- **Portabilidade**: Dados anonimizados podem ser transferidos
- **Elimina√ß√£o**: Dados originais podem ser eliminados ap√≥s anonimiza√ß√£o

## üõ†Ô∏è Ferramentas Utilizadas

### Bibliotecas Python
- **pandas**: Manipula√ß√£o de dados
- **numpy**: Opera√ß√µes num√©ricas
- **anonymization-library**: T√©cnicas de anonimiza√ß√£o
- **faker**: Gera√ß√£o de dados sint√©ticos
- **matplotlib/seaborn**: Visualiza√ß√µes

### T√©cnicas de Anonimiza√ß√£o
- **ARX**: Framework de anonimiza√ß√£o (refer√™ncia)
- **IBM Guardian**: Solu√ß√£o empresarial (refer√™ncia)
- **Google TensorFlow Privacy**: Privacidade diferencial (refer√™ncia)

## üìö Refer√™ncias

### Legisla√ß√£o
- [Lei Geral de Prote√ß√£o de Dados Pessoais (LGPD)](https://www.planalto.gov.br/ccivil_03/_ato2015-2018/2018/lei/l13709.htm)
- [Resolu√ß√£o ANPD n¬∫ 1/2023](https://www.gov.br/anpd/pt-br/documentos-e-publicacoes/resolucao-anpd-n-1-de-2023.pdf)

### T√©cnicas de Anonimiza√ß√£o
- Samarati, P., & Sweeney, L. (1998). Protecting privacy when disclosing information: k-anonymity and its enforcement through generalization and suppression.
- Machanavajjhala, A., et al. (2007). l-diversity: Privacy beyond k-anonymity.
- Dwork, C. (2006). Differential privacy.

### Ferramentas
- [ARX Data Anonymization Tool](https://arx.deidentifier.org/)
- [IBM Guardian](https://www.ibm.com/security/data-privacy)
- [TensorFlow Privacy](https://github.com/tensorflow/privacy)

## üë• Autores

- **Luiz Carlos Camargo** - Professor Orientador
- **Equipe de Desenvolvimento** - Implementa√ß√£o das t√©cnicas

## üìÖ Cronograma

- **Desenvolvimento**: Outubro 2024
- **Apresenta√ß√£o**: 27/10/2024
- **Entrega**: Teams (por um dos membros da dupla)

## ‚ö†Ô∏è Considera√ß√µes Importantes

### Limita√ß√µes
- Dados sint√©ticos para demonstra√ß√£o
- T√©cnicas aplicadas em ambiente controlado
- Necess√°ria valida√ß√£o para dados reais

### Recomenda√ß√µes
- Avaliar trade-off utilidade vs privacidade
- Considerar contexto espec√≠fico da aplica√ß√£o
- Implementar auditoria e monitoramento
- Revisar periodicamente as t√©cnicas aplicadas

## üìû Suporte

Para d√∫vidas ou sugest√µes sobre o projeto, entre em contato atrav√©s do Teams da disciplina.

---

**‚ö†Ô∏è Aviso Legal**: Este projeto √© para fins educacionais e de demonstra√ß√£o. Para aplica√ß√£o em dados reais, consulte especialistas em prote√ß√£o de dados e legisla√ß√£o aplic√°vel.
